OK ğŸ‘ â€” avec cette capture on voit **exactement pourquoi Ã§a casse**.

ğŸ‘‰ Tu lances Spark **en mode client depuis CodeHub**, mais ta config Kubernetes nâ€™expose pas correctement le **driver** aux executors.

Et Ã§a correspond parfaitement Ã  ton erreur prÃ©cÃ©dente :

```
UnknownHostException
Failed to connect ... :4401
```

---

# ğŸ¯ Le vrai problÃ¨me

Tu fais :

```python
.master("k8s://https://iks-ap43783...")
```

â¡ï¸ **mode client implicite** (puisque lancÃ© depuis notebook CodeHub).

Donc :

âœ… Driver = dans le notebook CodeHub
âœ… Executors = pods Kubernetes

âš ï¸ MAIS :

> les executors doivent pouvoir joindre le driver via un hostname routable.

Actuellement â†’ **ils ne peuvent pas rÃ©soudre lâ€™adresse du driver**.

---

# ğŸ§  Pourquoi Ã§a ne marche pas

En mode **client**, Spark fait :

```
Executor pod  --->  Driver (ton notebook)
```

Mais ton driver :

* tourne hors du cluster K8s
* nâ€™a pas dâ€™adresse DNS interne Kubernetes
* nâ€™expose pas spark.driver.host

Donc Kubernetes essaie de joindre un hostname invalide â†’ ğŸ’¥ DNS failure.

---

# ğŸ”¥ Indice dans tes logs

Avant tu avais :

```
UnknownHostException: codemub-xxxxx
```

ğŸ‘‰ Câ€™est le hostname auto-dÃ©tectÃ© du notebook.

Kubernetes ne connaÃ®t PAS ce hostname.

---

# âœ… Solution (2 options)

## â­ OPTION 1 â€” RECOMMANDÃ‰E (90% des cas)

ğŸ‘‰ Passe en **cluster mode**.

Câ€™est la bonne pratique avec Spark on Kubernetes.

### Ajoute :

```python
.config("spark.submit.deployMode", "cluster")
```

OU via spark-submit :

```bash
--deploy-mode cluster
```

---

### Ce que Ã§a change

```
AVANT
Notebook (driver) âŒ
        â†‘
Executors (K8s)

APRÃˆS
Driver pod (K8s) âœ…
        â†‘
Executors (K8s)
```

â¡ï¸ Tout reste dans Kubernetes â†’ DNS OK.

---

## â­ OPTION 2 â€” garder client mode (plus compliquÃ©)

Tu dois dÃ©finir explicitement :

```python
.config("spark.driver.host", "<IP accessible depuis K8s>")
.config("spark.driver.bindAddress", "0.0.0.0")
.config("spark.driver.port", "7078")
```

ET :

* ouvrir les ports rÃ©seau
* rendre CodeHub accessible depuis le cluster
* gÃ©rer firewall / NAT

ğŸ‘‰ honnÃªtement : **douleur garantie** ğŸ˜„

---

# âœ… Correction minimale de ton code

Ajoute juste :

```python
spark = (
    SparkSession.builder
    .appName(name)
    .master("k8s://https://iks-ap43783.svc-np.paas.echonet.net.intra:30633")
    .config("spark.submit.deployMode", "cluster")   # â­ AJOUT
    .config("spark.kubernetes.namespace", KUBE_NS)
    ...
    .getOrCreate()
)
```

---

# âš ï¸ TrÃ¨s important (souvent oubliÃ©)

En cluster mode, ton image doit contenir :

* ton code Python
* dÃ©pendances
* libs

Sinon driver pod ne trouvera pas ton notebook/script.

---

# ğŸ§© Pourquoi Ã§a marchait pas (rÃ©sumÃ© ultra court)

| Ã‰lÃ©ment   | Situation            |
| --------- | -------------------- |
| Mode      | client               |
| Driver    | CodeHub              |
| Executors | Kubernetes           |
| DNS       | impossible           |
| RÃ©sultat  | UnknownHostException |

---

# ğŸš€ Ce que je te conseille (niveau Data Engineer)

ğŸ‘‰ **Spark + Kubernetes + Notebook = toujours cluster mode**.

Client mode est quasi uniquement pour debug local.

---

Si tu veux, je peux aussi te montrer **la config production propre** utilisÃ©e en entreprise (avec driver service auto + retry + logs propres).
Dis juste ğŸ‘.
